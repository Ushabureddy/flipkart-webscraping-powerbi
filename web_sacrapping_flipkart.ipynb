{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fadb5c19-bbce-48da-b72b-e18770eb5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time, random\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "CATEGORIES = [\"mobiles\", \"laptops\"]\n",
    "PAGES_PER_CATEGORY = 10\n",
    "PLATFORM = \"Flipkart\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee298e4-04a3-4fa9-b485-40311de46376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- DRIVER ----------------\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00ca3a9f-d941-4948-b2e1-f591b4f368d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_get_text(prod, selectors, default=\"\"):\n",
    "    \"\"\"\n",
    "    Tries multiple CSS selectors and returns the first matching element's text.\n",
    "    If none found, returns default.\n",
    "    \"\"\"\n",
    "    for selector in selectors:\n",
    "        try:\n",
    "            return prod.find_element(By.CSS_SELECTOR, selector).text\n",
    "        except:\n",
    "            continue\n",
    "    return default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd6d5bb-3679-4a73-a9ec-0e324ae8e92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping category: mobiles\n",
      "Found 24 products on page 1\n",
      "Found 24 products on page 2\n",
      "Found 24 products on page 3\n",
      "Found 24 products on page 4\n",
      "Found 24 products on page 5\n",
      "Found 24 products on page 6\n",
      "Found 24 products on page 7\n",
      "Found 24 products on page 8\n",
      "Found 24 products on page 9\n",
      "Found 24 products on page 10\n",
      "Scraping category: laptops\n",
      "Found 24 products on page 1\n",
      "Found 24 products on page 2\n",
      "Found 24 products on page 3\n",
      "Found 24 products on page 4\n",
      "Found 24 products on page 5\n",
      "Found 24 products on page 6\n",
      "Found 24 products on page 7\n",
      "Found 24 products on page 8\n",
      "Found 24 products on page 9\n",
      "Found 24 products on page 10\n"
     ]
    }
   ],
   "source": [
    "product_list = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    print(f\"Scraping category: {category}\")\n",
    "    \n",
    "    for page in range(1, PAGES_PER_CATEGORY + 1):\n",
    "        url = f\"https://www.flipkart.com/search?q={category}&page={page}\"\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(2,4))\n",
    "        \n",
    "        # Close login popup if present\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, \"//button[contains(text(),'✕')]\").click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Get product cards\n",
    "        products = driver.find_elements(By.CSS_SELECTOR, \"a.CGtC98\")\n",
    "        print(f\"Found {len(products)} products on page {page}\")\n",
    "        \n",
    "        for prod in products:\n",
    "            try:\n",
    "                # Product Name & Brand\n",
    "                name = safe_get_text(prod, [\"div.KzDlHZ\", \"div._4rR01T\"])\n",
    "                brand = name.split()[0] if name else \"\"\n",
    "                \n",
    "                # Current Price\n",
    "                current_price_text = safe_get_text(prod, [\"div.Nx9bqj._4b5DiR\", \"div._30jeq3\"])\n",
    "                current_price = float(current_price_text.replace(\"₹\",\"\").replace(\",\",\"\")) if current_price_text else 0\n",
    "                \n",
    "                # Original Price\n",
    "                original_price_text = safe_get_text(prod, [\"div.yRaY8j.ZYYwLA\", \"div._3I9_wc\"])\n",
    "                original_price = float(original_price_text.replace(\"₹\",\"\").replace(\",\",\"\")) if original_price_text else 0\n",
    "                \n",
    "                # Discount\n",
    "                discount = safe_get_text(prod, [\"div.UkUFwK span\", \"div._3Ay6Sb span\"])\n",
    "                \n",
    "                # Rating\n",
    "                rating_text = safe_get_text(prod, [\"div.XQDdHH\", \"div._3LWZlK\"])\n",
    "                try:\n",
    "                    rating = float(rating_text) if rating_text else 0\n",
    "                except:\n",
    "                    rating = 0\n",
    "                \n",
    "                # Reviews\n",
    "                reviews = safe_get_text(prod, [\"span.Wphh3N\", \"span._2_R_DZ\"])\n",
    "                \n",
    "                # URL\n",
    "                product_url = prod.get_attribute(\"href\")\n",
    "                \n",
    "                scrape_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "                \n",
    "                product_list.append({\n",
    "                    \"Product_Name\": name,\n",
    "                    \"Brand\": brand,\n",
    "                    \"Current_Price\": current_price,\n",
    "                    \"Original_Price\": original_price,\n",
    "                    \"Discount(%)\": discount,\n",
    "                    \"Rating\": rating,\n",
    "                    \"Reviews_Count\": reviews,\n",
    "                    \"Platform\": PLATFORM,\n",
    "                    \"Category\": category,\n",
    "                    \"Product_URL\": product_url,\n",
    "                    \"Scrape_Date\": scrape_date\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(\"Error scraping product:\", e)\n",
    "                print(\"Product HTML:\", prod.get_attribute(\"outerHTML\")[:500])  # debug first 500 chars\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a136541b-8c28-4375-a0eb-1b3d4d7a2ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scraping complete! Total products: 480. Saved to flipkart_products.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "df = pd.DataFrame(product_list)\n",
    "df.to_csv(\"flipkart_products.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(f\" Scraping complete! Total products: {len(df)}. Saved to flipkart_products.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a4780d5-93fd-4750-8033-bbcd78138fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d426b-15cd-4e6a-bea7-03f43e17f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
